{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python-headless in /Users/ame/Library/Python/3.9/lib/python/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from opencv-python-headless) (2.0.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in /Users/ame/Library/Python/3.9/lib/python/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from seaborn) (2.0.2)\n",
      "Requirement already satisfied: pandas>=1.2 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from seaborn) (3.9.4)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (6.5.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.56.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn) (3.23.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from pandas>=1.2->seaborn) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /Users/ame/Library/Python/3.9/lib/python/site-packages (3.9.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: pillow>=8 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.23.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /Users/ame/Library/Python/3.9/lib/python/site-packages (1.6.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.5.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python-headless\n",
    "%pip install seaborn\n",
    "%pip install matplotlib\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "batch_size = 32\n",
    "learning_rate = 0.000001\n",
    "epochs = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 646 files belonging to 2 classes.\n",
      "Found 248 files belonging to 2 classes.\n",
      "Found 102 files belonging to 2 classes.\n",
      "Images shape: (32, 224, 224, 3)\n",
      "Labels shape: (32, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-26 18:31:23.088668: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "baseDir = \"./datasets/uti-no-uti/\"\n",
    "os.listdir(baseDir)\n",
    "\n",
    "# Load training and validation datasets\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    baseDir + \"train\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",  # Use categorical for multi-class classification\n",
    "    image_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    baseDir + \"dev\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Test dataset (assuming separate directory for test data)\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    baseDir + \"test\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False  # No shuffling for test set\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.RandomContrast(factor=0.2),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "    tf.keras.layers.RandomRotation(0.1)\n",
    "]) # Light Augmentation\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(data_augmentation(x, training=True)), y))\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ResNet50V2 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
     ]
    }
   ],
   "source": [
    "ResNet50V2 = tf.keras.applications.ResNet50V2(input_shape = (224,224,3), include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    tf.keras.Input(shape=(224, 224, 3)),  # 🔹 Explicit input layer\n",
    "    ResNet50V2,\n",
    "    Flatten(),\n",
    "    Dense(2, activation='softmax')  # Final classification layer\n",
    "])\n",
    "\n",
    "# Call model to initialize input shape\n",
    "model.build(input_shape=(None, 224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='categorical_crossentropy',  # Suitable for binary classification\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "\u001b[1m179/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.5622 - loss: 1.0993 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 18:22:55.422522: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_9', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 470ms/step - accuracy: 0.5626 - loss: 1.0982 - val_accuracy: 0.5000 - val_loss: 1.4793\n",
      "Epoch 2/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 319ms/step - accuracy: 0.6722 - loss: 0.8567 - val_accuracy: 0.4990 - val_loss: 1.3432\n",
      "Epoch 3/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 317ms/step - accuracy: 0.7337 - loss: 0.6835 - val_accuracy: 0.5119 - val_loss: 1.4663\n",
      "Epoch 4/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 317ms/step - accuracy: 0.7637 - loss: 0.6159 - val_accuracy: 0.5876 - val_loss: 1.1317\n",
      "Epoch 5/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 313ms/step - accuracy: 0.8008 - loss: 0.5121 - val_accuracy: 0.7380 - val_loss: 0.6397\n",
      "Epoch 6/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 315ms/step - accuracy: 0.8034 - loss: 0.5015 - val_accuracy: 0.8283 - val_loss: 0.4140\n",
      "Epoch 7/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 318ms/step - accuracy: 0.8364 - loss: 0.4363 - val_accuracy: 0.8507 - val_loss: 0.3741\n",
      "Epoch 8/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 315ms/step - accuracy: 0.8342 - loss: 0.4240 - val_accuracy: 0.8604 - val_loss: 0.3591\n",
      "Epoch 9/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 314ms/step - accuracy: 0.8515 - loss: 0.3877 - val_accuracy: 0.8699 - val_loss: 0.3422\n",
      "Epoch 10/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 316ms/step - accuracy: 0.8691 - loss: 0.3483 - val_accuracy: 0.8737 - val_loss: 0.3271\n",
      "Epoch 11/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 315ms/step - accuracy: 0.8748 - loss: 0.3390 - val_accuracy: 0.8789 - val_loss: 0.3133\n",
      "Epoch 12/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 316ms/step - accuracy: 0.8884 - loss: 0.2985 - val_accuracy: 0.8918 - val_loss: 0.2897\n",
      "Epoch 13/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 313ms/step - accuracy: 0.8883 - loss: 0.3085 - val_accuracy: 0.8985 - val_loss: 0.2705\n",
      "Epoch 14/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 315ms/step - accuracy: 0.8964 - loss: 0.2861 - val_accuracy: 0.8995 - val_loss: 0.2619\n",
      "Epoch 15/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 314ms/step - accuracy: 0.9025 - loss: 0.2599 - val_accuracy: 0.9016 - val_loss: 0.2517\n",
      "Epoch 16/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 314ms/step - accuracy: 0.9011 - loss: 0.2666 - val_accuracy: 0.9089 - val_loss: 0.2390\n",
      "Epoch 17/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 316ms/step - accuracy: 0.9059 - loss: 0.2440 - val_accuracy: 0.9145 - val_loss: 0.2303\n",
      "Epoch 18/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 314ms/step - accuracy: 0.9037 - loss: 0.2482 - val_accuracy: 0.9163 - val_loss: 0.2191\n",
      "Epoch 19/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 315ms/step - accuracy: 0.9141 - loss: 0.2304 - val_accuracy: 0.9211 - val_loss: 0.2118\n",
      "Epoch 20/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 316ms/step - accuracy: 0.9195 - loss: 0.2070 - val_accuracy: 0.9278 - val_loss: 0.1995\n",
      "Epoch 21/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 315ms/step - accuracy: 0.9158 - loss: 0.2207 - val_accuracy: 0.9295 - val_loss: 0.1917\n",
      "Epoch 22/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 314ms/step - accuracy: 0.9320 - loss: 0.1858 - val_accuracy: 0.9306 - val_loss: 0.1899\n",
      "Epoch 23/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 315ms/step - accuracy: 0.9303 - loss: 0.1772 - val_accuracy: 0.9355 - val_loss: 0.1762\n",
      "Epoch 24/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 314ms/step - accuracy: 0.9420 - loss: 0.1602 - val_accuracy: 0.9351 - val_loss: 0.1770\n",
      "Epoch 25/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 316ms/step - accuracy: 0.9341 - loss: 0.1623 - val_accuracy: 0.9379 - val_loss: 0.1692\n",
      "Epoch 26/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 316ms/step - accuracy: 0.9372 - loss: 0.1623 - val_accuracy: 0.9386 - val_loss: 0.1676\n",
      "Epoch 27/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 313ms/step - accuracy: 0.9442 - loss: 0.1618 - val_accuracy: 0.9431 - val_loss: 0.1587\n",
      "Epoch 28/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 314ms/step - accuracy: 0.9506 - loss: 0.1345 - val_accuracy: 0.9442 - val_loss: 0.1530\n",
      "Epoch 29/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 314ms/step - accuracy: 0.9443 - loss: 0.1433 - val_accuracy: 0.9445 - val_loss: 0.1510\n",
      "Epoch 30/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 317ms/step - accuracy: 0.9558 - loss: 0.1283 - val_accuracy: 0.9473 - val_loss: 0.1446\n",
      "Epoch 31/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 317ms/step - accuracy: 0.9435 - loss: 0.1478 - val_accuracy: 0.9477 - val_loss: 0.1396\n",
      "Epoch 32/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 316ms/step - accuracy: 0.9528 - loss: 0.1206 - val_accuracy: 0.9480 - val_loss: 0.1395\n",
      "Epoch 33/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 315ms/step - accuracy: 0.9612 - loss: 0.1012 - val_accuracy: 0.9515 - val_loss: 0.1319\n",
      "Epoch 34/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 318ms/step - accuracy: 0.9467 - loss: 0.1343 - val_accuracy: 0.9564 - val_loss: 0.1257\n",
      "Epoch 35/35\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 316ms/step - accuracy: 0.9592 - loss: 0.1091 - val_accuracy: 0.9557 - val_loss: 0.1256\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=epochs, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy and loss\n",
    "def plot_metrics(history, save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Accuracy plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, 'accuracy_plot.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Loss plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, 'loss_plot.png'))\n",
    "    plt.close()\n",
    "\n",
    "plot_metrics(history, 'output/graphs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on test data...\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - accuracy: 0.9268 - loss: 0.1594\n",
      "Test Loss: 0.1247\n",
      "Test Accuracy: 0.9478\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 134ms/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, roc_curve, auc, precision_recall_fscore_support, matthews_corrcoef, cohen_kappa_score, balanced_accuracy_score, jaccard_score, log_loss, fbeta_score\n",
    ")\n",
    "\n",
    "path = \"results/unu/resnet50v2/\"\n",
    "name = \"UNU_ResNet50V2_Round1\" # Rounds are retrains for ANOVA\n",
    "\n",
    "# Ensure the results directory exists\n",
    "results_dir = path + name + \"/\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "model.save(results_dir + name + \".keras\")\n",
    "\n",
    "# Save training metrics (loss and accuracy)\n",
    "def save_training_metrics(history, results_dir):\n",
    "    # Plot training & validation accuracy\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(results_dir, \"training_accuracy.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot training & validation loss\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig(os.path.join(results_dir, \"training_loss.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Save training and validation metrics in a text file\n",
    "    with open(os.path.join(results_dir, \"training_validation_metrics.txt\"), \"w\") as f:\n",
    "        f.write(\"Training and Validation Metrics Per Epoch\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        for i, (acc, val_acc, loss, val_loss) in enumerate(zip(\n",
    "            history.history['accuracy'], history.history['val_accuracy'], \n",
    "            history.history['loss'], history.history['val_loss']\n",
    "        )):\n",
    "            f.write(f\"Epoch {i+1}:\\n\")\n",
    "            f.write(f\"  Training Accuracy: {acc:.4f}, Validation Accuracy: {val_acc:.4f}\\n\")\n",
    "            f.write(f\"  Training Loss: {loss:.4f}, Validation Loss: {val_loss:.4f}\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "# Generate confusion matrix\n",
    "def save_confusion_matrix(y_true, y_pred, class_names, results_dir):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.savefig(os.path.join(results_dir, \"confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Generate ROC curve\n",
    "def save_roc_curve(y_true, y_probs, results_dir):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(results_dir, \"roc_curve.png\"))\n",
    "    plt.close()\n",
    "\n",
    "def save_classification_metrics(y_true, y_pred, y_probs, results_dir, class_names):\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn)  # Sensitivity = Recall\n",
    "    specificity = tn / (tn + fp)  # Specificity\n",
    "\n",
    "    # Compute additional metrics\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    jaccard = jaccard_score(y_true, y_pred, average='binary')\n",
    "    logloss = log_loss(y_true, y_probs)\n",
    "    fbeta = fbeta_score(y_true, y_pred, beta=0.5)  # Example for F0.5-score\n",
    "\n",
    "    # Compute AUC\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Save metrics to a text file\n",
    "    with open(os.path.join(results_dir, \"classification_metrics.txt\"), \"w\") as f:\n",
    "        f.write(f\"Precision: {precision:.4f}\\n\")\n",
    "        f.write(f\"Recall (Sensitivity): {recall:.4f}\\n\")\n",
    "        f.write(f\"F1-Score: {f1:.4f}\\n\")\n",
    "        f.write(f\"Sensitivity: {sensitivity:.4f}\\n\")\n",
    "        f.write(f\"Specificity: {specificity:.4f}\\n\")\n",
    "        f.write(f\"AUC: {roc_auc:.4f}\\n\")\n",
    "        f.write(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\\n\")\n",
    "        f.write(f\"Cohen's Kappa: {kappa:.4f}\\n\")\n",
    "        f.write(f\"Balanced Accuracy: {balanced_acc:.4f}\\n\")\n",
    "        f.write(f\"Jaccard Index (IoU): {jaccard:.4f}\\n\")\n",
    "        f.write(f\"Log Loss: {logloss:.4f}\\n\")\n",
    "        f.write(f\"F0.5-Score: {fbeta:.4f}\\n\")\n",
    "# Evaluate and save all metrics\n",
    "def save_model_metrics(model, test_ds, results_dir, class_names):\n",
    "    # Evaluate the model\n",
    "    print(\"Evaluating the model on test data...\")\n",
    "    test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Save test metrics to a text file\n",
    "    with open(os.path.join(results_dir, \"testing_metrics.txt\"), \"w\") as f:\n",
    "        f.write(f\"Test Loss: {test_loss:.4f}\\n\")\n",
    "        f.write(f\"Test Accuracy: {test_accuracy:.4f}\\n\")\n",
    "\n",
    "    # Generate predictions\n",
    "    y_true = np.concatenate([y for _, y in test_ds], axis=0)\n",
    "    y_probs = model.predict(test_ds)\n",
    "    y_pred = np.argmax(y_probs, axis=1)\n",
    "    y_true = np.argmax(y_true, axis=1)  # Assuming one-hot encoded labels\n",
    "\n",
    "    # Save confusion matrix\n",
    "    save_confusion_matrix(y_true, y_pred, class_names, results_dir)\n",
    "\n",
    "    # Save ROC curve\n",
    "    if len(class_names) == 2:  # Only valid for binary classification\n",
    "        save_roc_curve(y_true, y_probs[:, 1], results_dir)\n",
    "\n",
    "    # Save classification metrics\n",
    "    save_classification_metrics(y_true, y_pred, y_probs[:, 1], results_dir, class_names)\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `history` is the history object returned by `model.fit()`\n",
    "# and `test_ds` is your test dataset\n",
    "save_training_metrics(history, results_dir)\n",
    "save_model_metrics(model, test_ds, results_dir, class_names=class_names)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2763641,
     "sourceId": 4774750,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
