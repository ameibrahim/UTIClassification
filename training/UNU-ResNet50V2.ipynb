{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python-headless in /Users/ame/Library/Python/3.9/lib/python/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from opencv-python-headless) (2.0.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in /Users/ame/Library/Python/3.9/lib/python/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from seaborn) (2.0.2)\n",
      "Requirement already satisfied: pandas>=1.2 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from seaborn) (3.9.4)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (6.5.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.56.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn) (3.23.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from pandas>=1.2->seaborn) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /Users/ame/Library/Python/3.9/lib/python/site-packages (3.9.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: pillow>=8 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.23.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /Users/ame/Library/Python/3.9/lib/python/site-packages (1.6.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/ame/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.5.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python-headless\n",
    "%pip install seaborn\n",
    "%pip install matplotlib\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "batch_size = 32\n",
    "learning_rate = 0.000001\n",
    "epochs = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 646 files belonging to 2 classes.\n",
      "Found 248 files belonging to 2 classes.\n",
      "Found 102 files belonging to 2 classes.\n",
      "Images shape: (32, 224, 224, 3)\n",
      "Labels shape: (32, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-26 18:31:23.088668: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "baseDir = \"./datasets/uti-no-uti/\"\n",
    "os.listdir(baseDir)\n",
    "\n",
    "# Load training and validation datasets\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    baseDir + \"train\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",  # Use categorical for multi-class classification\n",
    "    image_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    baseDir + \"dev\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Test dataset (assuming separate directory for test data)\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    baseDir + \"test\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False  # No shuffling for test set\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.RandomContrast(factor=0.2),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "    tf.keras.layers.RandomRotation(0.1)\n",
    "]) # Light Augmentation\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(data_augmentation(x, training=True)), y))\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ResNet50V2 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94668760/94668760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m398s\u001b[0m 4us/step\n"
     ]
    }
   ],
   "source": [
    "ResNet50V2 = tf.keras.applications.ResNet50V2(input_shape = (224,224,3), include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    tf.keras.Input(shape=(224, 224, 3)),  # 🔹 Explicit input layer\n",
    "    ResNet50V2,\n",
    "    Flatten(),\n",
    "    Dense(2, activation='softmax')  # Final classification layer\n",
    "])\n",
    "\n",
    "# Call model to initialize input shape\n",
    "model.build(input_shape=(None, 224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='categorical_crossentropy',  # Suitable for binary classification\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 11s/step - accuracy: 0.5625 - loss: 1.1557 - val_accuracy: 0.4194 - val_loss: 1.5642\n",
      "Epoch 2/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 10s/step - accuracy: 0.5709 - loss: 0.9865 - val_accuracy: 0.3669 - val_loss: 1.4007\n",
      "Epoch 3/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 10s/step - accuracy: 0.6030 - loss: 0.9241 - val_accuracy: 0.3347 - val_loss: 1.4589\n",
      "Epoch 4/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 11s/step - accuracy: 0.6859 - loss: 0.7304 - val_accuracy: 0.3306 - val_loss: 1.6554\n",
      "Epoch 5/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 9s/step - accuracy: 0.7053 - loss: 0.6524 - val_accuracy: 0.3266 - val_loss: 1.7583\n",
      "Epoch 6/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 10s/step - accuracy: 0.7785 - loss: 0.4872 - val_accuracy: 0.3145 - val_loss: 1.7730\n",
      "Epoch 7/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 10s/step - accuracy: 0.7810 - loss: 0.4866 - val_accuracy: 0.3024 - val_loss: 1.7380\n",
      "Epoch 8/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 10s/step - accuracy: 0.7965 - loss: 0.4551 - val_accuracy: 0.3347 - val_loss: 1.6310\n",
      "Epoch 9/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 13s/step - accuracy: 0.8506 - loss: 0.3956 - val_accuracy: 0.3508 - val_loss: 1.4648\n",
      "Epoch 10/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 19s/step - accuracy: 0.8701 - loss: 0.3356 - val_accuracy: 0.3750 - val_loss: 1.2730\n",
      "Epoch 11/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 14s/step - accuracy: 0.8648 - loss: 0.3241 - val_accuracy: 0.3952 - val_loss: 1.1608\n",
      "Epoch 12/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 11s/step - accuracy: 0.8527 - loss: 0.3574 - val_accuracy: 0.4435 - val_loss: 1.0728\n",
      "Epoch 13/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 11s/step - accuracy: 0.8919 - loss: 0.2944 - val_accuracy: 0.5040 - val_loss: 0.9755\n",
      "Epoch 14/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 10s/step - accuracy: 0.9204 - loss: 0.2167 - val_accuracy: 0.5444 - val_loss: 0.8846\n",
      "Epoch 15/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 10s/step - accuracy: 0.8729 - loss: 0.2877 - val_accuracy: 0.5887 - val_loss: 0.7844\n",
      "Epoch 16/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 11s/step - accuracy: 0.9035 - loss: 0.2281 - val_accuracy: 0.6371 - val_loss: 0.7067\n",
      "Epoch 17/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 13s/step - accuracy: 0.9180 - loss: 0.2056 - val_accuracy: 0.6976 - val_loss: 0.6055\n",
      "Epoch 18/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 13s/step - accuracy: 0.9380 - loss: 0.1620 - val_accuracy: 0.7177 - val_loss: 0.5432\n",
      "Epoch 19/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 10s/step - accuracy: 0.9125 - loss: 0.2308 - val_accuracy: 0.7540 - val_loss: 0.5029\n",
      "Epoch 20/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 9s/step - accuracy: 0.9116 - loss: 0.2109 - val_accuracy: 0.7581 - val_loss: 0.4932\n",
      "Epoch 21/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 9s/step - accuracy: 0.9132 - loss: 0.2227 - val_accuracy: 0.7984 - val_loss: 0.4458\n",
      "Epoch 22/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 17s/step - accuracy: 0.9150 - loss: 0.2207 - val_accuracy: 0.8226 - val_loss: 0.3976\n",
      "Epoch 23/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 12s/step - accuracy: 0.9224 - loss: 0.2063 - val_accuracy: 0.8508 - val_loss: 0.3327\n",
      "Epoch 24/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 13s/step - accuracy: 0.9398 - loss: 0.1578 - val_accuracy: 0.8508 - val_loss: 0.2881\n",
      "Epoch 25/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 12s/step - accuracy: 0.9128 - loss: 0.2079 - val_accuracy: 0.8831 - val_loss: 0.2349\n",
      "Epoch 26/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 16s/step - accuracy: 0.9598 - loss: 0.1119 - val_accuracy: 0.9113 - val_loss: 0.1956\n",
      "Epoch 27/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 18s/step - accuracy: 0.9374 - loss: 0.1355 - val_accuracy: 0.9395 - val_loss: 0.1678\n",
      "Epoch 28/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 21s/step - accuracy: 0.9448 - loss: 0.1284 - val_accuracy: 0.9194 - val_loss: 0.1595\n",
      "Epoch 29/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 13s/step - accuracy: 0.9472 - loss: 0.1431 - val_accuracy: 0.9395 - val_loss: 0.1454\n",
      "Epoch 30/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 11s/step - accuracy: 0.9455 - loss: 0.1487 - val_accuracy: 0.9476 - val_loss: 0.1428\n",
      "Epoch 31/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 16s/step - accuracy: 0.9372 - loss: 0.1693 - val_accuracy: 0.9516 - val_loss: 0.1354\n",
      "Epoch 32/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 14s/step - accuracy: 0.9494 - loss: 0.1090 - val_accuracy: 0.9476 - val_loss: 0.1272\n",
      "Epoch 33/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 15s/step - accuracy: 0.9415 - loss: 0.1363 - val_accuracy: 0.9556 - val_loss: 0.1233\n",
      "Epoch 34/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 14s/step - accuracy: 0.9640 - loss: 0.1102 - val_accuracy: 0.9597 - val_loss: 0.1248\n",
      "Epoch 35/35\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 12s/step - accuracy: 0.9681 - loss: 0.0918 - val_accuracy: 0.9597 - val_loss: 0.1189\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=epochs, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy and loss\n",
    "def plot_metrics(history, save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Accuracy plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, 'accuracy_plot.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Loss plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, 'loss_plot.png'))\n",
    "    plt.close()\n",
    "\n",
    "plot_metrics(history, 'output/graphs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on test data...\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6s/step - accuracy: 0.8806 - loss: 0.1952\n",
      "Test Loss: 0.1716\n",
      "Test Accuracy: 0.9020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-26 21:37:16.457681: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 10s/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, roc_curve, auc, precision_recall_fscore_support, matthews_corrcoef, cohen_kappa_score, balanced_accuracy_score, jaccard_score, log_loss, fbeta_score\n",
    ")\n",
    "\n",
    "path = \"results/unu/resnet50v2/\"\n",
    "name = \"UNU_ResNet50V2_Round1\" # Rounds are retrains for ANOVA\n",
    "\n",
    "# Ensure the results directory exists\n",
    "results_dir = path + name + \"/\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "model.save(results_dir + name + \".keras\")\n",
    "\n",
    "# Save training metrics (loss and accuracy)\n",
    "def save_training_metrics(history, results_dir):\n",
    "    # Plot training & validation accuracy\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(results_dir, \"training_accuracy.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot training & validation loss\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig(os.path.join(results_dir, \"training_loss.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Save training and validation metrics in a text file\n",
    "    with open(os.path.join(results_dir, \"training_validation_metrics.txt\"), \"w\") as f:\n",
    "        f.write(\"Training and Validation Metrics Per Epoch\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        for i, (acc, val_acc, loss, val_loss) in enumerate(zip(\n",
    "            history.history['accuracy'], history.history['val_accuracy'], \n",
    "            history.history['loss'], history.history['val_loss']\n",
    "        )):\n",
    "            f.write(f\"Epoch {i+1}:\\n\")\n",
    "            f.write(f\"  Training Accuracy: {acc:.4f}, Validation Accuracy: {val_acc:.4f}\\n\")\n",
    "            f.write(f\"  Training Loss: {loss:.4f}, Validation Loss: {val_loss:.4f}\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "# Generate confusion matrix\n",
    "def save_confusion_matrix(y_true, y_pred, class_names, results_dir):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.savefig(os.path.join(results_dir, \"confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Generate ROC curve\n",
    "def save_roc_curve(y_true, y_probs, results_dir):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(results_dir, \"roc_curve.png\"))\n",
    "    plt.close()\n",
    "\n",
    "def save_classification_metrics(y_true, y_pred, y_probs, results_dir, class_names):\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn)  # Sensitivity = Recall\n",
    "    specificity = tn / (tn + fp)  # Specificity\n",
    "\n",
    "    # Compute additional metrics\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    jaccard = jaccard_score(y_true, y_pred, average='binary')\n",
    "    logloss = log_loss(y_true, y_probs)\n",
    "    fbeta = fbeta_score(y_true, y_pred, beta=0.5)  # Example for F0.5-score\n",
    "\n",
    "    # Compute AUC\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Save metrics to a text file\n",
    "    with open(os.path.join(results_dir, \"classification_metrics.txt\"), \"w\") as f:\n",
    "        f.write(f\"Precision: {precision:.4f}\\n\")\n",
    "        f.write(f\"Recall (Sensitivity): {recall:.4f}\\n\")\n",
    "        f.write(f\"F1-Score: {f1:.4f}\\n\")\n",
    "        f.write(f\"Sensitivity: {sensitivity:.4f}\\n\")\n",
    "        f.write(f\"Specificity: {specificity:.4f}\\n\")\n",
    "        f.write(f\"AUC: {roc_auc:.4f}\\n\")\n",
    "        f.write(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\\n\")\n",
    "        f.write(f\"Cohen's Kappa: {kappa:.4f}\\n\")\n",
    "        f.write(f\"Balanced Accuracy: {balanced_acc:.4f}\\n\")\n",
    "        f.write(f\"Jaccard Index (IoU): {jaccard:.4f}\\n\")\n",
    "        f.write(f\"Log Loss: {logloss:.4f}\\n\")\n",
    "        f.write(f\"F0.5-Score: {fbeta:.4f}\\n\")\n",
    "# Evaluate and save all metrics\n",
    "def save_model_metrics(model, test_ds, results_dir, class_names):\n",
    "    # Evaluate the model\n",
    "    print(\"Evaluating the model on test data...\")\n",
    "    test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Save test metrics to a text file\n",
    "    with open(os.path.join(results_dir, \"testing_metrics.txt\"), \"w\") as f:\n",
    "        f.write(f\"Test Loss: {test_loss:.4f}\\n\")\n",
    "        f.write(f\"Test Accuracy: {test_accuracy:.4f}\\n\")\n",
    "\n",
    "    # Generate predictions\n",
    "    y_true = np.concatenate([y for _, y in test_ds], axis=0)\n",
    "    y_probs = model.predict(test_ds)\n",
    "    y_pred = np.argmax(y_probs, axis=1)\n",
    "    y_true = np.argmax(y_true, axis=1)  # Assuming one-hot encoded labels\n",
    "\n",
    "    # Save confusion matrix\n",
    "    save_confusion_matrix(y_true, y_pred, class_names, results_dir)\n",
    "\n",
    "    # Save ROC curve\n",
    "    if len(class_names) == 2:  # Only valid for binary classification\n",
    "        save_roc_curve(y_true, y_probs[:, 1], results_dir)\n",
    "\n",
    "    # Save classification metrics\n",
    "    save_classification_metrics(y_true, y_pred, y_probs[:, 1], results_dir, class_names)\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `history` is the history object returned by `model.fit()`\n",
    "# and `test_ds` is your test dataset\n",
    "save_training_metrics(history, results_dir)\n",
    "save_model_metrics(model, test_ds, results_dir, class_names=class_names)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2763641,
     "sourceId": 4774750,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
