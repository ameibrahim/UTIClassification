{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python-headless\n",
    "%pip install seaborn\n",
    "%pip install matplotlib\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, roc_curve, auc, precision_recall_fscore_support, matthews_corrcoef, cohen_kappa_score, balanced_accuracy_score, jaccard_score, log_loss, fbeta_score\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "learning_rate = 0.000001\n",
    "group_type = \"unu\"\n",
    "model_name = \"ResNet101V2\"\n",
    "baseDir = \"./datasets/uti-no-uti/\"\n",
    "os.listdir(baseDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training metrics (loss and accuracy)\n",
    "def save_training_metrics(history, results_dir):\n",
    "    # Plot training & validation accuracy\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(results_dir, \"training_accuracy.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot training & validation loss\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig(os.path.join(results_dir, \"training_loss.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Save training and validation metrics in a text file\n",
    "    with open(os.path.join(results_dir, \"training_validation_metrics.txt\"), \"w\") as f:\n",
    "        f.write(\"Training and Validation Metrics Per Epoch\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        for i, (acc, val_acc, loss, val_loss) in enumerate(zip(\n",
    "            history.history['accuracy'], history.history['val_accuracy'], \n",
    "            history.history['loss'], history.history['val_loss']\n",
    "        )):\n",
    "            f.write(f\"Epoch {i+1}:\\n\")\n",
    "            f.write(f\"  Training Accuracy: {acc:.4f}, Validation Accuracy: {val_acc:.4f}\\n\")\n",
    "            f.write(f\"  Training Loss: {loss:.4f}, Validation Loss: {val_loss:.4f}\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "# Generate confusion matrix\n",
    "def save_confusion_matrix(y_true, y_pred, class_names, results_dir):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.savefig(os.path.join(results_dir, \"confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Generate ROC curve\n",
    "def save_roc_curve(y_true, y_probs, results_dir):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(results_dir, \"roc_curve.png\"))\n",
    "    plt.close()\n",
    "\n",
    "def save_classification_metrics(y_true, y_pred, y_probs, results_dir, class_names):\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn)  # Sensitivity = Recall\n",
    "    specificity = tn / (tn + fp)  # Specificity\n",
    "\n",
    "    # Compute additional metrics\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    jaccard = jaccard_score(y_true, y_pred, average='binary')\n",
    "    logloss = log_loss(y_true, y_probs)\n",
    "    fbeta = fbeta_score(y_true, y_pred, beta=0.5)  # Example for F0.5-score\n",
    "\n",
    "    # Compute AUC\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Save metrics to a text file\n",
    "    with open(os.path.join(results_dir, \"classification_metrics.txt\"), \"w\") as f:\n",
    "        f.write(f\"Precision: {precision:.4f}\\n\")\n",
    "        f.write(f\"Recall (Sensitivity): {recall:.4f}\\n\")\n",
    "        f.write(f\"F1-Score: {f1:.4f}\\n\")\n",
    "        f.write(f\"Sensitivity: {sensitivity:.4f}\\n\")\n",
    "        f.write(f\"Specificity: {specificity:.4f}\\n\")\n",
    "        f.write(f\"AUC: {roc_auc:.4f}\\n\")\n",
    "        f.write(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\\n\")\n",
    "        f.write(f\"Cohen's Kappa: {kappa:.4f}\\n\")\n",
    "        f.write(f\"Balanced Accuracy: {balanced_acc:.4f}\\n\")\n",
    "        f.write(f\"Jaccard Index (IoU): {jaccard:.4f}\\n\")\n",
    "        f.write(f\"Log Loss: {logloss:.4f}\\n\")\n",
    "        f.write(f\"F0.5-Score: {fbeta:.4f}\\n\")\n",
    "# Evaluate and save all metrics\n",
    "def save_model_metrics(model, test_ds, results_dir, class_names):\n",
    "    # Evaluate the model\n",
    "    print(\"Evaluating the model on test data...\")\n",
    "    test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Save test metrics to a text file\n",
    "    with open(os.path.join(results_dir, \"testing_metrics.txt\"), \"w\") as f:\n",
    "        f.write(f\"Test Loss: {test_loss:.4f}\\n\")\n",
    "        f.write(f\"Test Accuracy: {test_accuracy:.4f}\\n\")\n",
    "\n",
    "    # Generate predictions\n",
    "    y_true = np.concatenate([y for _, y in test_ds], axis=0)\n",
    "    y_probs = model.predict(test_ds)\n",
    "    y_pred = np.argmax(y_probs, axis=1)\n",
    "    y_true = np.argmax(y_true, axis=1)  # Assuming one-hot encoded labels\n",
    "\n",
    "    # Save confusion matrix\n",
    "    save_confusion_matrix(y_true, y_pred, class_names, results_dir)\n",
    "\n",
    "    # Save ROC curve\n",
    "    if len(class_names) == 2:  # Only valid for binary classification\n",
    "        save_roc_curve(y_true, y_probs[:, 1], results_dir)\n",
    "\n",
    "    # Save classification metrics\n",
    "    save_classification_metrics(y_true, y_pred, y_probs[:, 1], results_dir, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA requires that you don't have a seed.\n",
    "\n",
    "def get_images_and_classes():\n",
    "    # Load training and validation datasets\n",
    "\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        baseDir + \"train\",\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"categorical\",  # Use categorical for multi-class classification\n",
    "        image_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        baseDir + \"dev\",\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"categorical\",\n",
    "        image_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    # Test dataset (assuming separate directory for test data)\n",
    "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        baseDir + \"test\",\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"categorical\",\n",
    "        image_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # No shuffling for test set\n",
    "    )\n",
    "\n",
    "    class_names = train_ds.class_names\n",
    "\n",
    "    for images, labels in train_ds.take(1):\n",
    "        print(f\"Images shape: {images.shape}\")\n",
    "        print(f\"Labels shape: {labels.shape}\")\n",
    "    \n",
    "    return (train_ds, val_ds, test_ds, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.RandomContrast(factor=0.2),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "    tf.keras.layers.RandomRotation(0.1)\n",
    "]) # Light Augmentation\n",
    "\n",
    "def augment_and_normalize(_train_ds, _val_ds, _test_ds):\n",
    "    internal_train_ds = _train_ds.map(lambda x, y: (normalization_layer(data_augmentation(x, training=True)), y))\n",
    "    internal_val_ds = _val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "    internal_test_ds = _test_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    output_train_ds = internal_train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    output_val_ds = internal_val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    output_test_ds = internal_test_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return (output_train_ds, output_val_ds, output_test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ResNet50V2 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_compile_model():\n",
    "    ResNet101V2 = tf.keras.applications.ResNet101V2(input_shape = (224,224,3), include_top=False)\n",
    "\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(224, 224, 3)),  # 🔹 Explicit input layer\n",
    "        ResNet101V2,\n",
    "        Flatten(),\n",
    "        Dense(2, activation='softmax')  # Final classification layer\n",
    "    ])\n",
    "\n",
    "    # Call model to initialize input shape\n",
    "    model.build(input_shape=(None, 224, 224, 3))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='categorical_crossentropy',  # Suitable for binary classification\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 8/21\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:28\u001b[0m 11s/step - accuracy: 0.5957 - loss: 0.8699"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "ANOVA_REPEATS = 5\n",
    "epochs = 35\n",
    "\n",
    "for index in range(1, ANOVA_REPEATS + 1):\n",
    "    print(\"REPEAT ROUND: \", index)\n",
    "\n",
    "    (train_ds, val_ds, test_ds, class_names) = get_images_and_classes()\n",
    "    (output_train_ds, output_val_ds, output_test_ds) = augment_and_normalize(train_ds, val_ds, test_ds)\n",
    "    model = create_and_compile_model()\n",
    "\n",
    "    history = model.fit(output_train_ds, epochs=epochs, validation_data=output_val_ds)\n",
    "\n",
    "    path = \"results/\" + group_type + \"/\" + model_name +\"/\"\n",
    "    name = group_type.upper() + \"_\" + model_name +\"_Round\" + str(index) # Rounds are retrains for ANOVA\n",
    "\n",
    "    # Ensure the results directory exists\n",
    "    results_dir = path + name + \"/\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    model.save(results_dir + name + \".keras\")\n",
    "\n",
    "    save_training_metrics(history, results_dir)\n",
    "    save_model_metrics(model, output_test_ds, results_dir, class_names=class_names)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2763641,
     "sourceId": 4774750,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
